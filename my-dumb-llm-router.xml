<?xml version="1.0"?>
<Container version="2">
  <Name>dumb-llm-router</Name>
  <Repository>aidrak/dumb-llm-router</Repository>
  <Registry>ghcr.io/aidrak/dumb-llm-router:latest</Registry>
  <Network>bridge</Network>
  <MyIP/>
  <Shell>sh</Shell>
  <Privileged>false</Privileged>
  <Support>https://github.com/aidrak/dumb-llm-router/issues</Support>
  <Project>https://github.com/aidrak/dumb-llm-router</Project>
  <Overview>Dumb LLM Router - Intelligent routing system for multiple AI providers (OpenAI, Gemini, Anthropic, Perplexity). Automatically selects the best model based on request complexity, research needs, and context. Perfect for OpenWebUI integration.</Overview>
  <Category>Productivity: Tools:</Category>
  <WebUI>http://[IP]:[PORT:8000]/health</WebUI>
  <TemplateURL>https://raw.githubusercontent.com/aidrak/dumb-llm-router/main/unraid-template.xml</TemplateURL>
  <Icon>https://raw.githubusercontent.com/aidrak/dumb-llm-router/main/icon.png</Icon>
  <ExtraParams>--security-opt no-new-privileges:true --cap-drop=ALL --cap-add=NET_BIND_SERVICE --read-only --tmpfs /tmp:noexec,nosuid,size=100m</ExtraParams>
  <PostArgs/>
  <CPUset/>
  <DateInstalled>1640995200</DateInstalled>
  <DonateText/>
  <DonateLink/>
  <Requires/>
  <Config Name="Host Port" Target="8000" Default="8000" Mode="tcp" Description="Port for accessing the Dumb LLM Router API" Type="Port" Display="always" Required="true" Mask="false">8000</Config>
  <Config Name="Config Directory" Target="/config" Default="/mnt/user/appdata/dumb-llm-router/config" Mode="rw" Description="Configuration files directory" Type="Path" Display="always" Required="true" Mask="false">/mnt/user/appdata/dumb-llm-router/config</Config>
  <Config Name="Temp Directory" Target="/app/tmp" Default="/mnt/user/appdata/dumb-llm-router/tmp" Mode="rw" Description="Temporary files directory" Type="Path" Display="advanced" Required="false" Mask="false">/mnt/user/appdata/dumb-llm-router/tmp</Config>
  <Config Name="OpenAI API Key" Target="OPENAI_API_KEY" Default="" Mode="" Description="Your OpenAI API key (required for GPT models)" Type="Variable" Display="always" Required="true" Mask="true"></Config>
  <Config Name="Gemini API Key" Target="GEMINI_API_KEY" Default="" Mode="" Description="Your Google Gemini API key (required for Gemini models)" Type="Variable" Display="always" Required="true" Mask="true"></Config>
  <Config Name="Anthropic API Key" Target="ANTHROPIC_API_KEY" Default="" Mode="" Description="Your Anthropic API key (optional, for Claude models)" Type="Variable" Display="always" Required="false" Mask="true"></Config>
  <Config Name="Perplexity API Key" Target="PERPLEXITY_API_KEY" Default="" Mode="" Description="Your Perplexity API key (optional, for research queries)" Type="Variable" Display="always" Required="false" Mask="true"></Config>
  <Config Name="Ollama Host" Target="OLLAMA_API_HOST" Default="http://localhost:11434" Mode="" Description="Ollama API endpoint (if using local models)" Type="Variable" Display="always" Required="false" Mask="false">http://localhost:11434</Config>
  <Config Name="OpenWebUI URL" Target="OPENWEBUI_URL" Default="http://localhost:3000" Mode="" Description="OpenWebUI URL for integration" Type="Variable" Display="always" Required="false" Mask="false">http://localhost:3000</Config>
  <Config Name="Log Level" Target="LOG_LEVEL" Default="INFO" Mode="" Description="Logging level (DEBUG, INFO, WARNING, ERROR)" Type="Variable" Display="advanced" Required="false" Mask="false">INFO</Config>
  <Config Name="PUID" Target="PUID" Default="99" Mode="" Description="User ID for file permissions" Type="Variable" Display="advanced" Required="false" Mask="false">99</Config>
  <Config Name="PGID" Target="PGID" Default="100" Mode="" Description="Group ID for file permissions" Type="Variable" Display="advanced" Required="false" Mask="false">100</Config>
</Container>
